{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results_example/X_train.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 5377)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/X_train.pkl', 'rb') as file:\n",
    "    X_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769\n",
      "1537\n",
      "2305\n",
      "3073\n",
      "3841\n",
      "4609\n",
      "5377\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    print(1+i*768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=80)\n",
    "X_description_pca = pca.fit_transform(X_train[:, 1:769])\n",
    "pca = PCA(n_components=80)\n",
    "X_inclusion_pca = pca.fit_transform(X_train[:, 769:1537])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00548419, -0.00421741, -0.00513141, ..., -0.00566057,\n",
       "       -0.00465036, -0.00529177])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.48418630e-03,  2.07992998e+00, -1.09566611e+00, ...,\n",
       "        -5.76867569e-02,  1.38180805e-01, -9.36282265e-02],\n",
       "       [-4.21741350e-03,  1.04926631e+00, -1.02716205e+00, ...,\n",
       "         4.64628456e-01, -1.10033571e-01, -4.57400238e-02],\n",
       "       [-5.13141413e-03, -1.84473822e+00,  5.29840416e-01, ...,\n",
       "        -4.16255969e-01, -3.05884870e-01, -9.06071340e-02],\n",
       "       ...,\n",
       "       [-5.66057239e-03,  8.19845076e-01, -4.64275200e-01, ...,\n",
       "         2.63984794e-02, -1.70322387e-01,  3.30412524e-02],\n",
       "       [-4.65036117e-03,  1.97439599e+00, -1.84794664e+00, ...,\n",
       "         2.71659852e-01,  5.16461913e-02, -9.03792689e-02],\n",
       "       [-5.29176512e-03, -5.11180168e+00,  6.83578652e-01, ...,\n",
       "        -8.93148388e-02,  6.05417266e-02, -1.22867497e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((X_train[:, [0]], X_description_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "model = load('./results/model_rf.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/X_train_pca.pkl', 'rb') as file:\n",
    "    X_train_pca = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 11:13:23.981248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-13 11:13:23.993523: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-13 11:13:23.997218: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-13 11:13:24.007623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 11:13:24.824933: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./results/model_cnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/X_test.pkl', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "\n",
    "with open('./results/y_test.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/X_train_pca.pkl', 'rb') as file:\n",
    "    X_train_pca = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104201, 351, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.reshape(-1, 351, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': 20,\n",
       " 'max_features': 1.0,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404.7429081997575"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pickle_files(directory_path):\n",
    "    df_list = []\n",
    "    file_names = ['description2embedding.pkl',\n",
    "                  'eligibility2embedding.pkl',\n",
    "                  'treatment2embedding.pkl',\n",
    "                  'disease2embedding.pkl',\n",
    "                  'outcome2embedding.pkl']\n",
    "\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            p = pd.DataFrame(pickle.load(f))\\\n",
    "                .set_index('nctId')\n",
    "            df_list.append(p)\n",
    "\n",
    "    combined_df = pd.concat(df_list, axis=1, join=\"inner\")\n",
    "    combined_df.reset_index(inplace=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine_pickle_files('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168559, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168456, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_cols(combined_df):\n",
    "    separated_df = pd.concat([combined_df[['nctId', 'enrollment']],\n",
    "            combined_df['description_embedding'].apply(pd.Series),\n",
    "            combined_df['inclusion_embedding'].apply(pd.Series),\n",
    "            combined_df['exclusion_embedding'].apply(pd.Series),\n",
    "            combined_df['treatment_embedding'].apply(pd.Series),\n",
    "            combined_df['disease_embedding'].apply(pd.Series),\n",
    "            combined_df['measures_embedding'].apply(pd.Series),\n",
    "            combined_df['timeframes_embedding'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    return separated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/disease2embedding.pkl', \"rb\") as f:\n",
    "    data = pd.DataFrame(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nctId</th>\n",
       "      <th>disease_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT03202394</td>\n",
       "      <td>[0.14991804957389832, 0.22459396719932556, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT02138214</td>\n",
       "      <td>[-0.020751827706893284, 0.2324144939581553, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nctId                                  disease_embedding\n",
       "0  NCT03202394  [0.14991804957389832, 0.22459396719932556, -0....\n",
       "1  NCT02138214  [-0.020751827706893284, 0.2324144939581553, -0..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nctId</th>\n",
       "      <th>measures_embedding</th>\n",
       "      <th>timeframes_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT03202394</td>\n",
       "      <td>[-0.04192572832107544, -0.11662426590919495, -...</td>\n",
       "      <td>[0.27893149852752686, -0.09838172048330307, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT02138214</td>\n",
       "      <td>[0.0962123335339129, -0.03012945014052093, -0....</td>\n",
       "      <td>[0.17500807121541584, 0.024294625967741013, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nctId                                 measures_embedding  \\\n",
       "0  NCT03202394  [-0.04192572832107544, -0.11662426590919495, -...   \n",
       "1  NCT02138214  [0.0962123335339129, -0.03012945014052093, -0....   \n",
       "\n",
       "                                timeframes_embedding  \n",
       "0  [0.27893149852752686, -0.09838172048330307, -0...  \n",
       "1  [0.17500807121541584, 0.024294625967741013, -0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.core.indexes.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data_example/y_train.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Load data from the file\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas.core.indexes.numeric'"
     ]
    }
   ],
   "source": [
    "with open('./data_example/X_train.pkl', 'rb') as file:\n",
    "    # Load data from the file\n",
    "    X_train = pickle.load(file)\n",
    "    \n",
    "with open('./data_example/y_train.pkl', 'rb') as file:\n",
    "    # Load data from the file\n",
    "    y_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 5377)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_train_test_incompleted_ids('./data_all/clinIDs_parsed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(file_path):\n",
    "    df = pd.read_pickle(file_path)\n",
    "\n",
    "    X = pd.concat([df['enrollment'],\n",
    "                   df['description_embedding'].apply(pd.Series),\n",
    "                   df['inclusion_embedding'].apply(pd.Series),\n",
    "                   df['exclusion_embedding'].apply(pd.Series),\n",
    "                   df['treatment_embedding'].apply(pd.Series),\n",
    "                   df['disease_embedding'].apply(pd.Series),\n",
    "                   df['measures_embedding'].apply(pd.Series),\n",
    "                   df['timeframes_embedding'].apply(pd.Series)], axis=1)\n",
    "    y = df['durationMonths']\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = prepare_dataset('./data_example/train_df.pkl')\n",
    "X_test, y_test = prepare_dataset('./data_example/test_df.pkl')\n",
    "X_incompleted, y_incompleted = prepare_dataset('./data_example/incompleted_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize enrollment\n",
    "scaler = StandardScaler()\n",
    "X_train_enroll_scaled = scaler.fit_transform(X_train[['enrollment']])\n",
    "X_train_scaled = np.concatenate([X_train_enroll_scaled, X_train.iloc[:, 1:].values], axis=1)\n",
    "\n",
    "X_test_enroll_scaled = scaler.transform(X_test[['enrollment']])\n",
    "X_test_scaled = np.concatenate([X_test_enroll_scaled, X_test.iloc[:, 1:].values], axis=1)\n",
    "\n",
    "X_incompleted_enroll_scaled = scaler.transform(X_incompleted[['enrollment']])\n",
    "X_incompleted_scaled = np.concatenate([X_incompleted_enroll_scaled, X_incompleted.iloc[:, 1:].values], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling training\n",
    "model_ridge = Ridge()\n",
    "param_grid = {'alpha': [0.1, 1.0, 10.0]}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_ridge,\n",
    "    param_grid=param_grid, cv=5,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_model_ridge = grid_search.best_estimator_\n",
    "\n",
    "# Evaluation\n",
    "y_pred_ridge = best_model_ridge.predict(X_test_scaled)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Tune the parameter\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_rf,\n",
    "    param_distributions=param_grid, \n",
    "    n_iter=10, cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "best_model_rf = random_search.best_estimator_\n",
    "\n",
    "# Evaluation\n",
    "y_pred_rf = best_model_rf.predict(X_test_scaled)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost regressor\n",
    "model_xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Tune the parameter\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_xgb,\n",
    "    param_distributions=param_grid, \n",
    "    n_iter=10, cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "best_model_xgb = random_search.best_estimator_\n",
    "\n",
    "# Evaluation\n",
    "y_pred_xgb = best_model_xgb.predict(X_test_scaled)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an explainer object using the XGBoost model\n",
    "explainer = shap.Explainer(best_model_xgb)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate SHAP values for groups of features\n",
    "sections = ['enrollment', 'description', 'inclusion', 'exclusion',\n",
    "            'treatment', 'disease', 'measure', 'timeframe']\n",
    "\n",
    "section_shap_values = {}\n",
    "\n",
    "for i, section in enumerate(sections):\n",
    "    if section == 'enrollment':\n",
    "        section_shap_value = shap_values.values[:, 0]\n",
    "    else:\n",
    "        start_idx = (i-1) * 768 + 1\n",
    "        end_idx = start_idx + 768\n",
    "        section_shap_value = np.sum(shap_values.values[:, start_idx:end_idx], axis=1)\n",
    "    \n",
    "    section_shap_values[section] = section_shap_value\n",
    "\n",
    "section_shap_values = pd.DataFrame(section_shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_ffnn = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_ffnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define callbacks (optional but recommended for saving the best model)\n",
    "checkpoint = ModelCheckpoint('./results/ffnn_model.keras', monitor='val_loss',\n",
    "                             save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model_ffnn.fit(X_train_scaled, y_train,\n",
    "               epochs=50, batch_size=32,\n",
    "               validation_data=(X_test_scaled, y_test),\n",
    "               callbacks=[checkpoint])\n",
    "\n",
    "# Load the best saved model\n",
    "model_ffnn = load_model('./results/ffnn_model.keras')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ffnn = model_ffnn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_cnn = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define callbacks (optional)\n",
    "checkpoint = ModelCheckpoint('./results/cnn_model.keras', monitor='val_loss',\n",
    "                             save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model_cnn.fit(X_train_scaled, y_train,\n",
    "              epochs=50, batch_size=32,\n",
    "              validation_data=(X_test_scaled, y_test),\n",
    "              callbacks=[checkpoint])\n",
    "\n",
    "# Load the best saved model\n",
    "model_cnn = load_model('./results/cnn_model.keras')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_cnn = model_cnn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model_lstm = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define callbacks (optional)\n",
    "checkpoint = ModelCheckpoint('./results/lstm_model.keras', monitor='val_loss',\n",
    "                             save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model_cnn.fit(X_train_scaled, y_train,\n",
    "              epochs=50, batch_size=32,\n",
    "              validation_data=(X_test_scaled, y_test),\n",
    "              callbacks=[checkpoint])\n",
    "\n",
    "# Load the best saved model\n",
    "model_cnn = load_model('./results/lstm_model.keras')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_cnn = model_cnn.predict(X_test_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
